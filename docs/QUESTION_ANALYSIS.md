# Analisi delle Domande - Orientamento Utente vs Progettista

## üéØ Obiettivo del Sistema
**Far capire alle persone i rischi dell'utilizzo dell'IA**

L'obiettivo non √® formare tecnici che progettano sistemi AI, ma **educare utenti finali** su cosa significa utilizzare sistemi AI e quali rischi comportano.

---

## üìã Analisi delle Domande Attuali

### 1. Domande in CITY_ACTION_GROUPS (City Builder)

Queste sono le domande mostrate quando l'utente costruisce lo scenario:

#### ‚úÖ Buone (orientate all'utente)
- "Che tipo di informazioni raccogli?" 
- "Dove conservi i dati?"
- "Come vengono utilizzati i risultati?"

#### ‚ö†Ô∏è Problematiche (troppo tecniche)
- "Come analizzi queste informazioni?" ‚Üí presuppone conoscenze tecniche
- "Come proteggi i dati e chi pu√≤ accedervi?" ‚Üí richiede competenze di sicurezza informatica
- "Quali controlli e impatti vuoi monitorare?" ‚Üí troppo astratta

#### ‚ùå Critiche (orientate al progettista)
- "Addestramento di modelli di intelligenza artificiale" ‚Üí chi USA l'IA non addestra modelli
- "Crittografia dei dati, protezione degli accessi" ‚Üí dettagli tecnici per chi implementa

---

### 2. Domande in noteKnowledge.ts (Note sui Blocchi Rischio)

Queste appaiono quando l'utente clicca su un blocco di rischio:

#### ‚ùå TUTTE ORIENTATE AL PROGETTISTA

**Esempi critici**:

1. **"Chi verifica le decisioni del sistema? Con quale frequenza?"**
   - ‚úÖ Problema: Un utente finale che USA un chatbot non pu√≤ decidere chi verifica
   - ‚ùå Questa √® una domanda per chi PROGETTA il sistema
   - ‚ú® Dovrebbe essere: "Quando usi un chatbot, chi controlla le sue risposte?"

2. **"Hai minimizzato i dati raccolti? Usato pseudonimizzazione?"**
   - ‚úÖ Problema: L'utente che USA l'IA spesso non ha controllo su questo
   - ‚ùå Questa √® una domanda per chi RACCOGLIE i dati
   - ‚ú® Dovrebbe essere: "Sai quali dati il sistema raccoglie su di te?"

3. **"I dati sono cifrati? Chi ha accesso? Come rilevi intrusioni?"**
   - ‚úÖ Problema: Domanda per IT Security / DevOps
   - ‚ùå L'utente finale non sa rispondere a questa
   - ‚ú® Dovrebbe essere: "Sai dove vengono salvati i tuoi dati? Sono protetti?"

4. **"Hai documentato origine e contenuto del dataset? √à aggiornato?"**
   - ‚úÖ Problema: Chiara domanda per Data Scientist / ML Engineer
   - ‚ùå L'utente finale non addestra modelli
   - ‚ú® Dovrebbe essere: "Sai su quali dati √® stato addestrato il sistema che usi?"

5. **"Come rilevi quando il modello si degrada o produce output errati?"**
   - ‚úÖ Problema: Domanda per ML Ops / Data Engineer
   - ‚ùå L'utente finale non monitora modelli
   - ‚ú® Dovrebbe essere: "Come fai a capire se il sistema ti sta dando informazioni sbagliate?"

---

## üîç Problema Fondamentale

### Persona Attuale (sbagliata)
- **Chi**: Progettista/Developer/Security Officer
- **Ruolo**: Progetta, implementa, mantiene sistemi AI
- **Conoscenze**: Tecniche (ML, sicurezza, compliance)
- **Potere**: Pu√≤ modificare il sistema

### Persona Target (corretta)
- **Chi**: Utente finale / Cittadino / Dipendente / Consumatore
- **Ruolo**: USA sistemi AI (chatbot, raccomandazioni, ricerca)
- **Conoscenze**: Base, non tecniche
- **Potere**: Limitato, spesso solo pu√≤ scegliere se usare o meno

---

## üí° Raccomandazioni: Riformulare le Domande

### Principio Guida
**Le domande devono aiutare l'utente a:**
1. ‚úÖ Capire COSA sta facendo quando usa l'IA
2. ‚úÖ Identificare QUANDO ci sono rischi
3. ‚úÖ Sapere COME proteggersi
4. ‚úÖ Comprendere quali DIRITTI ha

**NON devono:**
- ‚ùå Chiedere come implementare sicurezza
- ‚ùå Richiedere competenze tecniche
- ‚ùå Presupporre controllo sul sistema

---

### Domande da Riformulare (noteKnowledge.ts)

#### Esempio 1: Supervisione Umana

**‚ùå ATTUALE** (per progettista):
```
"Chi verifica le decisioni del sistema? Con quale frequenza?"
```

**‚úÖ PROPOSTA** (per utente):
```
"Quando il sistema prende una decisione su di te (es. approvare un prestito), c'√® qualcuno che la controlla? Come puoi chiedere una revisione?"
```

**Oppure, pi√π semplice**:
```
"Se il sistema sbaglia, puoi chiedere a una persona di rivedere la decisione?"
```

---

#### Esempio 2: Privacy by Design

**‚ùå ATTUALE** (per progettista):
```
"Hai minimizzato i dati raccolti? Usato pseudonimizzazione?"
```

**‚úÖ PROPOSTA** (per utente):
```
"Quanti dati personali stai condividendo? Il sistema raccoglie solo quello che serve o anche di pi√π?"
```

**Oppure**:
```
"Conosci quali dati vengono salvati su di te? Potresti chiedere che ne raccolgano meno?"
```

---

#### Esempio 3: Sicurezza Informatica

**‚ùå ATTUALE** (per progettista):
```
"I dati sono cifrati? Chi ha accesso? Come rilevi intrusioni?"
```

**‚úÖ PROPOSTA** (per utente):
```
"Dove vengono salvati i tuoi dati? Sono protetti? Cosa succede se qualcuno li ruba?"
```

**Oppure**:
```
"Hai mai chiesto al fornitore del servizio come protegge i tuoi dati?"
```

---

#### Esempio 4: Dataset Ombra

**‚ùå ATTUALE** (per progettista):
```
"Hai documentato origine e contenuto del dataset? √à aggiornato?"
```

**‚úÖ PROPOSTA** (per utente):
```
"Su quali informazioni √® stato addestrato questo sistema? Potrebbero contenere pregiudizi o dati obsoleti?"
```

**Oppure, pi√π semplice**:
```
"Da dove vengono le informazioni che il sistema usa per funzionare? Potrebbero essere incomplete o sbagliate?"
```

---

#### Esempio 5: Monitoraggio Modelli

**‚ùå ATTUALE** (per progettista):
```
"Come rilevi quando il modello si degrada o produce output errati?"
```

**‚úÖ PROPOSTA** (per utente):
```
"Come fai a capire se il sistema ti sta dando informazioni sbagliate? Chi controlla che funzioni sempre bene?"
```

**Oppure**:
```
"Hai mai ricevuto risposte sbagliate dal sistema? Come le hai verificate?"
```

---

#### Esempio 6: Consenso

**‚ùå ATTUALE** (per progettista):
```
"Il consenso √® libero, specifico, informato e revocabile?"
```

**‚úÖ PROPOSTA** (per utente):
```
"Quando hai accettato di usare questo sistema, sapevi esattamente cosa avrebbero fatto con i tuoi dati? Puoi dire "no" quando vuoi?"
```

**Oppure**:
```
"Capisci cosa stai dando in cambio quando accetti di usare questo servizio? Puoi smettere quando vuoi?"
```

---

#### Esempio 7: Trasferimento Extra-UE

**‚ùå ATTUALE** (per progettista):
```
"Hai verificato che il paese destinatario abbia protezioni adeguate?"
```

**‚úÖ PROPOSTA** (per utente):
```
"I tuoi dati vengono salvati in Europa o all'estero? Sai quali rischi comporta salvarli fuori dall'UE?"
```

**Oppure**:
```
"Quando hai dato i tuoi dati, sapevi che potrebbero finire su server negli Stati Uniti o in altri paesi?"
```

---

## üìù Domande Alternative per CITY_ACTION_GROUPS

### ‚ùå Attuale: "Come proteggi i dati e chi pu√≤ accedervi?"

**‚úÖ Proposta 1** (pi√π semplice):
```
"DOMANDA: Chi pu√≤ vedere i tuoi dati?"
```

**‚úÖ Proposta 2** (orientata all'utente):
```
"DOMANDA: Hai controllo su chi accede ai tuoi dati?"
```

**Azioni proposte**:
- "Non lo so / Non ho controllo" ‚Üí Aggiunge rischio alto
- "Solo io e il fornitore del servizio" ‚Üí Aggiunge controllo base
- "Persone specifiche che autorizzo" ‚Üí Aggiunge controllo avanzato

---

### ‚ùå Attuale: "Come analizzi queste informazioni?"

**‚úÖ Proposta** (meno tecnica):
```
"DOMANDA: Come funziona il sistema che usi?"
```

**Azioni proposte**:
- "Un chatbot che risponde alle mie domande"
- "Un sistema che suggerisce contenuti (come Netflix)"
- "Un sistema che analizza documenti per me"
- "Un sistema che prende decisioni automatiche"

---

### ‚ùå Attuale: "Quali controlli e impatti vuoi monitorare?"

**‚úÖ Proposta**:
```
"DOMANDA: Quali rischi ti preoccupano di pi√π?"
```

**Azioni proposte**:
- "Che i miei dati vengano rubati o usati male"
- "Che il sistema prenda decisioni sbagliate su di me"
- "Che qualcuno mi discrimini o mi escluda"
- "Che il sistema consumi troppa energia"
- "Che nessuno controlli cosa fa il sistema"

---

## üéØ Categorie di Domande per Utenti Finali

### 1. **Consapevolezza** ("Cosa sto facendo?")
- "Che tipo di informazioni sto dando al sistema?"
- "Sapete dove vanno a finire i miei dati?"
- "Cosa fa esattamente questo sistema?"

### 2. **Rischi** ("Cosa pu√≤ andare storto?")
- "Cosa succede se il sistema sbaglia?"
- "I miei dati sono al sicuro?"
- "Posso essere discriminato da questo sistema?"

### 3. **Diritti** ("Cosa posso fare?")
- "Posso dire no quando voglio?"
- "Posso chiedere che cancellino i miei dati?"
- "Posso contestare una decisione automatica?"

### 4. **Controllo** ("Chi ha il potere?")
- "Chi controlla questo sistema?"
- "Chi pu√≤ vedere i miei dati?"
- "Chi risponde se qualcosa va storto?"

---

## üîÑ Struttura Proposta per noteKnowledge.ts

Invece di domande tecniche, usare:

### Formato: "Cosa significa per te?"

```typescript
'Supervisione Umana': {
  simpleExplanation: 'Non lasciare che sia solo la macchina a decidere...',
  
  // ‚ùå RIMUOVERE: question tecnica
  // question: 'Chi verifica le decisioni del sistema? Con quale frequenza?',
  
  // ‚úÖ AGGIUNGERE: domande per utente finale
  userQuestions: [
    "Se il sistema prende una decisione su di te (es. rifiuta un prestito), c'√® qualcuno che la controlla?",
    "Puoi chiedere che una persona umana riveda la decisione?",
    "Hai mai provato a contestare una decisione automatica?"
  ],
  
  // ‚úÖ AGGIUNGERE: cosa fare
  whatYouCanDo: [
    "Leggere le condizioni del servizio per vedere se c'√® revisione umana",
    "Chiedere al fornitore come puoi contestare decisioni automatiche",
    "Esercitare il tuo diritto GDPR (Art. 22) di non essere soggetto a decisioni solo automatiche"
  ],
  
  // ‚úÖ AGGIUNGERE: quando √® un problema
  redFlags: [
    "Il sistema decide tutto automaticamente senza possibilit√† di appello",
    "Non c'√® modo di parlare con una persona se qualcosa va storto",
    "Non ti hanno informato che le decisioni sono automatiche"
  ],
  
  // Mantenere regolamento per riferimento
  regulation: { ... }
}
```

---

## üìä Matrice: Attuale vs Proposta

| Categoria | Attuale (Progettista) | Proposta (Utente Finale) |
|-----------|----------------------|-------------------------|
| **Chi** | Chi progetta il sistema | Chi usa il sistema |
| **Focus** | Come implementare | Cosa significa per me |
| **Linguaggio** | Tecnico (cifratura, pseudonimizzazione) | Semplice (dati protetti, dati anonimi) |
| **Azione** | Configurare controlli | Capire rischi e diritti |
| **Domande** | "Come fai X?" | "Cosa significa per te X?" |
| **Obiettivo** | Compliance tecnica | Consapevolezza e empowerment |

---

## ‚úÖ Checklist per Nuove Domande

Prima di aggiungere una domanda, chiediti:

- [ ] Un utente NON tecnico pu√≤ rispondere?
- [ ] La domanda aiuta a capire un RISCHIO?
- [ ] Usa linguaggio semplice?
- [ ] Si concentra su "cosa significa per me" non "come implementare"?
- [ ] Aiuta a prendere decisioni informate?
- [ ] Non presuppone controllo tecnico sul sistema?

---

## üöÄ Prossimi Passi

1. **Riformulare noteKnowledge.ts** 
   - Convertire domande da tecniche a orientate utente
   - Aggiungere sezioni `userQuestions`, `whatYouCanDo`, `redFlags`

2. **Rivedere CITY_ACTION_GROUPS**
   - Semplificare domande tecniche
   - Aggiungere opzioni per utenti senza controllo tecnico

3. **Testare con utenti reali**
   - Verificare che utenti NON tecnici capiscano
   - Misurare se aumentano consapevolezza rischi

4. **Aggiungere strumenti di empowerment**
   - Non solo "sai che c'√® un rischio" ma "cosa puoi fare"
   - Link a diritti GDPR in linguaggio semplice
   - Template per chiedere informazioni ai fornitori

---

**Data Analisi**: 2024  
**Stato**: ‚ö†Ô∏è Richiede Riformulazione Domande
